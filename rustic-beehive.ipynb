{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup the notebook based on running environment.\n",
    "import os\n",
    "# Check for kaggle environment.\n",
    "if os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "    # Kaggle Run: update the system.\n",
    "    !pip uninstall -qqy google-ai-generativelanguage pydrive2 tensorflow tensorflow-decision-forests cryptography pyOpenSSL langchain langchain-core nltk ray click google-generativeai google-cloud-translate datasets cesium bigframes plotnine mlxtend fastai spacy thinc google-colab gcsfs jupyter-kernel-gateway nltk preprocessing gradio dopamine-rl torchtune\n",
    "    !pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    !pip install -qU langchain-community langchain-text-splitters google-adk google-adk[eval] google-cloud-translate Pillow\n",
    "    from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "else:\n",
    "    # Mock the kaggle secrets client.\n",
    "    class UserSecretsClient:\n",
    "        @classmethod\n",
    "        def set_secret(cls, id: str, value: str):\n",
    "            os.environ[id] = value\n",
    "        @classmethod\n",
    "        def get_secret(cls, id: str):\n",
    "            try:\n",
    "                return os.environ[id]\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError: authentication token for {id} is undefined\")\n",
    "    # Local Run: update the venv.\n",
    "    %pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    %pip install -qU langchain-community langchain-text-splitters pandas google-api-core ollama google-adk \"google-adk[eval]\" Pillow\n",
    "\n",
    "import asyncio, io, IPython, time\n",
    "from google import genai\n",
    "from google.api_core import retry, exceptions\n",
    "from google.genai.models import Models\n",
    "from google.genai import types, errors\n",
    "from io import BytesIO\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, errors.APIError) and e.code in {429, 503, 500})\n",
    "Models.generate_images = retry.Retry(predicate=is_retriable)(Models.generate_images)\n",
    "Models.generate_videos = retry.Retry(predicate=is_retriable)(Models.generate_videos)\n",
    "Models.generate_content = retry.Retry(predicate=is_retriable)(Models.generate_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img_in = Image.open(\"docs/src/vales_of_anduin_sketch.jpg\")\n",
    "\n",
    "prompt = \"\"\"Do something cool with this image to show off your skills.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cannot generate images or video.\n",
    "# But it can reason about them.\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-pro-preview\",\n",
    "    contents=[prompt, img_in],\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fantastic hand-drawn map of Middle-earth, specifically focusing on the Wilderland (Rhovanion) and Gondor.\n",
    "\n",
    "To \"show off,\" I‚Äôm not just going to describe the image‚ÄîI‚Äôm going to **analyze your specific cartographic choices** (which reveal you know your deep Tolkien lore) and then **convert your map into a functional code-based navigation system.**\n",
    "\n",
    "### 1. The \"Deep Lore\" Analysis\n",
    "You haven't just drawn the standard map from the back of *The Return of the King*. You‚Äôve drawn a map that likely reflects the **Second Age** or the very early **Third Age**, possibly from an Entish or Elvish perspective.\n",
    "\n",
    "*   **Evidence A: \"Lind√≥rinand\"**: You used the Nandorin name for Lothl√≥rien (\"Vale of the Land of the Singers\"). This name fell out of use after the Silvan Elves adopted Sindarin.\n",
    "*   **Evidence B: \"Ambar√≥na\" & \"Aldal√≥m√´\"**: These are Quenya names (meaning \"Eastern Earth\" and \"Tree-twilight\") famously used by Treebeard to describe the great forests before they were split into Fangorn and Mirkwood.\n",
    "*   **Evidence C: \"Greenwood\"**: You didn't label it \"Mirkwood,\" implying this map exists before the Shadow fell on the forest (approx. T.A. 1050).\n",
    "\n",
    "### 2. Gamifying Your Map (Python)\n",
    "I have converted the visual topology of your river systems (the pink lines) into a Python graph. The code below creates a text-based \"GPS\" that navigates the specific layout you drew, calculating danger levels based on the proximity to Mordor/Dol Guldur as shown in your sketch.\n",
    "\n",
    "```python\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "class MiddleEarthMap:\n",
    "    def __init__(self):\n",
    "        # Creating a directed graph based on the flow of rivers in your drawing\n",
    "        self.map_graph = nx.DiGraph()\n",
    "        self.setup_locations()\n",
    "        self.setup_river_routes()\n",
    "\n",
    "    def setup_locations(self):\n",
    "        # Locations identified from your handwriting via OCR analysis\n",
    "        self.locations = {\n",
    "            \"Ered Mithrin\": {\"type\": \"Mountain\", \"danger\": 7},\n",
    "            \"Erebor\": {\"type\": \"Stronghold\", \"danger\": 3},\n",
    "            \"Esgaroth\": {\"type\": \"City\", \"danger\": 4},\n",
    "            \"Greenwood Forest\": {\"type\": \"Forest\", \"danger\": 6},\n",
    "            \"Anduin Valley\": {\"type\": \"Plains\", \"danger\": 2},\n",
    "            \"Nen Hithoel\": {\"type\": \"Lake\", \"danger\": 5},\n",
    "            \"Falls of Rauros\": {\"type\": \"Waterfall\", \"danger\": 8},\n",
    "            \"Ud√ªn\": {\"type\": \"Evil\", \"danger\": 10},\n",
    "            \"Bay of Belfalas\": {\"type\": \"Ocean\", \"danger\": 1},\n",
    "        }\n",
    "\n",
    "    def setup_river_routes(self):\n",
    "        # Mapping the PINK lines you drew as navigable edges\n",
    "        # Format: (Start, End, Travel_Days)\n",
    "        routes = [\n",
    "            (\"Ered Mithrin\", \"Greenwood Forest\", 5),\n",
    "            (\"Erebor\", \"Esgaroth\", 2),\n",
    "            (\"Esgaroth\", \"Anduin Valley\", 6),\n",
    "            (\"Greenwood Forest\", \"Anduin Valley\", 4),\n",
    "            (\"Anduin Valley\", \"Nen Hithoel\", 5),\n",
    "            (\"Nen Hithoel\", \"Falls of Rauros\", 1),\n",
    "            (\"Falls of Rauros\", \"Bay of Belfalas\", 10) # The long stretch south\n",
    "        ]\n",
    "        self.map_graph.add_weighted_edges_from(routes)\n",
    "\n",
    "    def plan_journey(self, start, end):\n",
    "        try:\n",
    "            path = nx.shortest_path(self.map_graph, start, end, weight='weight')\n",
    "            total_danger = sum(self.locations[loc][\"danger\"] for loc in path)\n",
    "            \n",
    "            print(f\"üó∫Ô∏è  JOURNEY PLANNER: {start} -> {end}\")\n",
    "            print(f\"----------------------------------------\")\n",
    "            print(f\"üìç Route: {' -> '.join(path)}\")\n",
    "            print(f\"‚ö†Ô∏è  Cumulative Danger Rating: {total_danger}/50\")\n",
    "            \n",
    "            if \"Falls of Rauros\" in path:\n",
    "                print(\"‚ùó WARNING: Portage required at Falls of Rauros.\")\n",
    "            if \"Ud√ªn\" in path:\n",
    "                print(\"‚ò†Ô∏è  CRITICAL: One does not simply walk into this node.\")\n",
    "                \n",
    "        except nx.NetworkXNoPath:\n",
    "            print(f\"‚ùå No river route connects {start} to {end} on this map.\")\n",
    "\n",
    "# Let's run a simulation based on your map data\n",
    "navigator = MiddleEarthMap()\n",
    "\n",
    "# Scenario: A raft escaping the North to reach the Sea\n",
    "navigator.plan_journey(\"Erebor\", \"Bay of Belfalas\")\n",
    "```\n",
    "\n",
    "### 3. The Narrative Output\n",
    "Based on the code simulation and your drawing, here is the generated log for the route highlighted in pink:\n",
    "\n",
    "> **The Riverlog of the Lonely Mountain**\n",
    ">\n",
    "> We departed **Erebor** under the shadow of the Mountain. The current took us swiftly to **Esgaroth** (Long Lake). Following your map's pink contours, we merged into the Great River.\n",
    ">\n",
    "> To our right, the trees of **Lind√≥rinand** loomed‚Äîgolden and strange. To our left, the peaks of **Ered Lithui** jagged against the sky like broken teeth.\n",
    ">\n",
    "> The most treacherous point was the red-circled zone on your parchment: **Nen Hithoel**. The current accelerated. We barely made shore before the roar of the **Falls of Rauros**. From there, it was a long drift past the mouths of the Entwash (Onodl√≥) until the air turned salty and the White Mountains (Ered Nimrais) faded into the **Bay of Belfalas**.\n",
    "\n",
    "**Verdict:** Great work on the map. The inclusion of archaic geography (Aldal√≥m√´/Ambar√≥na) makes it a sophisticated piece of cartography!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Capable of editing and generating.\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-pro-image-preview\",\n",
    "    contents=[prompt, img_in],\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.text:\n",
    "        print(part.text)\n",
    "    elif part.inline_data is not None:\n",
    "        image = Image.open(BytesIO(part.inline_data.data))\n",
    "        image.save(\"docs/results/img_out.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_by_side(img1, img2, width=\"45%\", margin=\"2%\"):\n",
    "    html = f\"\"\"\n",
    "    <div style=\"\n",
    "        display:flex;\n",
    "        justify-content:center;\n",
    "        align-items:center;\n",
    "        gap:{margin};\n",
    "    \">\n",
    "        <img src=\"{img1}\" style=\"width:{width}; max-width:100%; height:auto;\">\n",
    "        <img src=\"{img2}\" style=\"width:{width}; max-width:100%; height:auto;\">\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return HTML(html)\n",
    "\n",
    "img_a = \"docs/src/vales_of_anduin_sketch.jpg\"\n",
    "img_b = \"docs/results/map_one_shot.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"\n",
       "        display:flex;\n",
       "        justify-content:center;\n",
       "        align-items:center;\n",
       "        gap:2%;\n",
       "    \">\n",
       "        <img src=\"docs/src/vales_of_anduin_sketch.jpg\" style=\"width:45%; max-width:100%; height:auto;\">\n",
       "        <img src=\"docs/results/map_one_shot.png\" style=\"width:45%; max-width:100%; height:auto;\">\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(side_by_side(img_a, img_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Can only generate, no editing.\n",
    "def generate_image(prompt):\n",
    "    result = client.models.generate_images(\n",
    "        model=\"imagen-4.0-ultra-generate-001\", # imagen-4.0-generate-001, imagen-4.0-fast-generate-001\n",
    "        prompt=prompt,\n",
    "        config=dict(aspect_ratio=\"16:9\", image_size=\"2k\") # person_generation=\"DONT_ALLOW\"\n",
    "    )\n",
    "    for n, generated_image in enumerate(result.generated_images):\n",
    "        generated_image.image.save(f\"docs/results/scene_{n}.jpg\")\n",
    "        generated_image.image.show()\n",
    "\n",
    "# Capable of editing and generating.\n",
    "def generate_video(image, prompt):\n",
    "    # Converting the image to bytes\n",
    "    image_bytes_io = io.BytesIO()\n",
    "    image.save(image_bytes_io, format=image.format)\n",
    "    image_bytes = image_bytes_io.getvalue()\n",
    "\n",
    "    operation = client.models.generate_videos(\n",
    "        model=\"veo-3.0-generate-001\", # veo-3.0-generate-001, veo-3.0-fast-generate-001\n",
    "        prompt=prompt,\n",
    "        image=types.Image(image_bytes=image_bytes, mime_type=image.format),\n",
    "        config=types.GenerateVideosConfig(\n",
    "            aspect_ratio=\"16:9\",\n",
    "            number_of_videos=1))\n",
    "    \n",
    "    while not operation.done:\n",
    "        print(\"Waiting for video generation to complete...\")\n",
    "        time.sleep(10)\n",
    "        operation = client.operations.get(operation)\n",
    "\n",
    "    return operation.result.generated_videos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Capable of editing and generating.\n",
    "result = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-image\", # gemini-2.5-flash-image-preview\n",
    "    contents=[prompt, img_in]\n",
    ")\n",
    "\n",
    "for part in result.candidates[0].content.parts:\n",
    "    if part.text:\n",
    "        print(part.text)\n",
    "    elif part.inline_data is not None:\n",
    "        image = Image.open(BytesIO(part.inline_data.data))\n",
    "        image.save(\"docs/results/img_out.png\")\n",
    "\n",
    "Image.open(\"docs/results/img_out.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lyria_client = genai.Client(\n",
    "    api_key=GOOGLE_API_KEY,\n",
    "    http_options={'api_version': 'v1alpha'}, # Lyria is only experimental.\n",
    ")\n",
    "\n",
    "music_prompts = [\n",
    "    {\"text\": \"Piano\", \"weight\": 2.0},\n",
    "    types.WeightedPrompt(text=\"Meditation\", weight=0.5),\n",
    "    types.WeightedPrompt(text=\"Live Performance\", weight=1.0),\n",
    "]\n",
    "\n",
    "music_config = types.LiveMusicGenerationConfig(\n",
    "    bpm=128,\n",
    "    scale=types.Scale.D_MAJOR_B_MINOR,\n",
    "    music_generation_mode=types.MusicGenerationMode.QUALITY\n",
    ")\n",
    "\n",
    "async def generate_music(prompts: list, config: types.LiveMusicGenerationConfig):\n",
    "    # Background task to process incoming audio.\n",
    "    async def receive_audio(session):\n",
    "        while True:\n",
    "            async for message in session.receive():\n",
    "                audio_data = message.server_content.audio_chunks[0].data\n",
    "                # Process audio...\n",
    "                await asyncio.sleep(10**-12)\n",
    "\n",
    "    async with (\n",
    "        lyria_client.aio.live.music.connect(model='models/lyria-realtime-exp') as session,\n",
    "        asyncio.TaskGroup() as tg,\n",
    "    ):\n",
    "        # Set up task to receive server messages.\n",
    "        tg.create_task(receive_audio(session))\n",
    "\n",
    "        # Send initial prompts and config\n",
    "        await session.set_weighted_prompts(prompts=music_prompts)\n",
    "        await session.set_music_generation_config(config=config)\n",
    "\n",
    "        # Start streaming music\n",
    "        await session.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "asyncio.run(generate_music(music_prompts, music_config))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
