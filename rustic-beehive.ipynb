{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Setup the notebook based on running environment.\nimport os\n# Check for kaggle environment.\nif os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n    # Kaggle Run: update the system.\n    !pip uninstall -qqy google-ai-generativelanguage pydrive2 tensorflow tensorflow-decision-forests cryptography pyOpenSSL langchain langchain-core nltk ray click google-generativeai google-cloud-translate datasets cesium bigframes plotnine mlxtend fastai spacy thinc google-colab gcsfs jupyter-kernel-gateway nltk preprocessing gradio dopamine-rl torchtune\n    !pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n    !pip install -qU langchain-community langchain-text-splitters google-adk google-adk[eval] google-cloud-translate Pillow\n    from kaggle_secrets import UserSecretsClient # type: ignore\nelse:\n    # Mock the kaggle secrets client.\n    class UserSecretsClient:\n        @classmethod\n        def set_secret(cls, id: str, value: str):\n            os.environ[id] = value\n        @classmethod\n        def get_secret(cls, id: str):\n            try:\n                return os.environ[id]\n            except KeyError as e:\n                print(f\"KeyError: authentication token for {id} is undefined\")\n    # Local Run: update the venv.\n    %pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n    %pip install -qU langchain-community langchain-text-splitters pandas google-api-core ollama google-adk \"google-adk[eval]\" Pillow\n\nimport asyncio, io, IPython, time\nfrom google import genai\nfrom google.api_core import retry, exceptions\nfrom google.genai.models import Models\nfrom google.genai import types, errors\nfrom io import BytesIO\nfrom PIL import Image\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\nis_retriable = lambda e: (isinstance(e, errors.APIError) and e.code in {429, 503, 500})\nModels.generate_images = retry.Retry(predicate=is_retriable)(Models.generate_images)\nModels.generate_videos = retry.Retry(predicate=is_retriable)(Models.generate_videos)\nModels.generate_content = retry.Retry(predicate=is_retriable)(Models.generate_content)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_in = Image.open(\"docs/src/vales_of_anduin_sketch.jpg\")\n\nprompt = \"\"\"Do something cool with this image to show off your skills.\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cannot generate images or video.\nresponse = client.models.generate_content(\n    model=\"gemini-3-pro-preview\",\n    contents=prompt,\n)\n\nprint(response.text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Capable of editing and generating.\nresponse = client.models.generate_content(\n    model=\"gemini-3-pro-image-preview\",\n    contents=prompt,\n)\n\nprint(response.text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Can only generate, no editing.\ndef generate_image(prompt):\n    result = client.models.generate_images(\n        model=\"imagen-4.0-ultra-generate-001\", # imagen-4.0-generate-001, imagen-4.0-fast-generate-001\n        prompt=prompt,\n        config=dict(aspect_ratio=\"16:9\", image_size=\"2k\") # person_generation=\"DONT_ALLOW\"\n    )\n    for n, generated_image in enumerate(result.generated_images):\n        generated_image.image.save(f\"docs/results/scene_{n}.jpg\")\n        generated_image.image.show()\n\n# Capable of editing and generating.\ndef generate_video(image, prompt):\n    # Converting the image to bytes\n    image_bytes_io = io.BytesIO()\n    image.save(image_bytes_io, format=image.format)\n    image_bytes = image_bytes_io.getvalue()\n\n    operation = client.models.generate_videos(\n        model=\"veo-3.0-generate-001\", # veo-3.0-generate-001, veo-3.0-fast-generate-001\n        prompt=prompt,\n        image=types.Image(image_bytes=image_bytes, mime_type=image.format),\n        config=types.GenerateVideosConfig(\n            aspect_ratio=\"16:9\",\n            number_of_videos=1))\n    \n    while not operation.done:\n        print(\"Waiting for video generation to complete...\")\n        time.sleep(10)\n        operation = client.operations.get(operation)\n\n    return operation.result.generated_videos[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Capable of editing and generating.\nresult = client.models.generate_content(\n    model=\"gemini-2.5-flash-image\", # gemini-2.5-flash-image-preview\n    contents=[prompt, img_in]\n)\n\nfor part in result.candidates[0].content.parts:\n    if part.text:\n        print(part.text)\n    elif part.inline_data is not None:\n        image = Image.open(BytesIO(part.inline_data.data))\n        image.save(\"docs/results/img_out.png\")\n\nImage.open(\"docs/results/img_out.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lyria_client = genai.Client(\n    api_key=GOOGLE_API_KEY,\n    http_options={'api_version': 'v1alpha'}, # Lyria is only experimental.\n)\n\nmusic_prompts = [\n    {\"text\": \"Piano\", \"weight\": 2.0},\n    types.WeightedPrompt(text=\"Meditation\", weight=0.5),\n    types.WeightedPrompt(text=\"Live Performance\", weight=1.0),\n]\n\nmusic_config = types.LiveMusicGenerationConfig(\n    bpm=128,\n    scale=types.Scale.D_MAJOR_B_MINOR,\n    music_generation_mode=types.MusicGenerationMode.QUALITY\n)\n\nasync def generate_music(prompts: list, config: types.LiveMusicGenerationConfig):\n    # Background task to process incoming audio.\n    async def receive_audio(session):\n        while True:\n            async for message in session.receive():\n                audio_data = message.server_content.audio_chunks[0].data\n                # Process audio...\n                await asyncio.sleep(10**-12)\n\n    async with (\n        lyria_client.aio.live.music.connect(model='models/lyria-realtime-exp') as session,\n        asyncio.TaskGroup() as tg,\n    ):\n        # Set up task to receive server messages.\n        tg.create_task(receive_audio(session))\n\n        # Send initial prompts and config\n        await session.set_weighted_prompts(prompts=music_prompts)\n        await session.set_music_generation_config(config=config)\n\n        # Start streaming music\n        await session.play()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"asyncio.run(generate_music(music_prompts, music_config))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}