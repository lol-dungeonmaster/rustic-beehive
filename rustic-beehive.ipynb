{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup the notebook based on running environment.\n",
    "import os\n",
    "# Check for kaggle environment.\n",
    "if os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "    # Kaggle Run: update the system.\n",
    "    !pip uninstall -qqy google-ai-generativelanguage pydrive2 tensorflow tensorflow-decision-forests cryptography pyOpenSSL langchain langchain-core nltk ray click google-generativeai google-cloud-translate datasets cesium bigframes plotnine mlxtend fastai spacy thinc google-colab gcsfs jupyter-kernel-gateway nltk preprocessing\n",
    "    !pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    !pip install -qU langchain-community langchain-text-splitters google-adk google-adk[eval] google-cloud-translate Pillow\n",
    "    from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "else:\n",
    "    # Mock the kaggle secrets client.\n",
    "    class UserSecretsClient:\n",
    "        @classmethod\n",
    "        def set_secret(cls, id: str, value: str):\n",
    "            os.environ[id] = value\n",
    "        @classmethod\n",
    "        def get_secret(cls, id: str):\n",
    "            try:\n",
    "                return os.environ[id]\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError: authentication token for {id} is undefined\")\n",
    "    # Local Run: update the venv.\n",
    "    %pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    %pip install -qU langchain-community langchain-text-splitters pandas google-api-core ollama google-adk \"google-adk[eval]\" Pillow\n",
    "\n",
    "import asyncio, io, IPython, time\n",
    "from google import genai\n",
    "from google.api_core import retry, exceptions\n",
    "from google.genai.models import Models\n",
    "from google.genai import types, errors\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, errors.APIError) and e.code in {429, 503, 500})\n",
    "Models.generate_images = retry.Retry(predicate=is_retriable)(Models.generate_images)\n",
    "Models.generate_videos = retry.Retry(predicate=is_retriable)(Models.generate_videos)\n",
    "Models.generate_content = retry.Retry(predicate=is_retriable)(Models.generate_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = Image.open(\"docs/src/vales_of_anduin_sketch.jpg\")\n",
    "\n",
    "prompt = \"\"\"Do something cool with this image to show off your skills.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot generate images or video.\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-pro-preview\",\n",
    "    contents=prompt,\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capable of editing and generating.\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-pro-image-preview\",\n",
    "    contents=prompt,\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can only generate, no editing.\n",
    "def generate_image(prompt):\n",
    "    result = client.models.generate_images(\n",
    "        model=\"imagen-4.0-ultra-generate-001\", # imagen-4.0-generate-001, imagen-4.0-fast-generate-001\n",
    "        prompt=prompt,\n",
    "        config=dict(aspect_ratio=\"16:9\", image_size=\"2k\") # person_generation=\"DONT_ALLOW\"\n",
    "    )\n",
    "    for n, generated_image in enumerate(result.generated_images):\n",
    "        generated_image.image.save(f\"docs/results/scene_{n}.jpg\")\n",
    "        generated_image.image.show()\n",
    "\n",
    "# Capable of editing and generating.\n",
    "def generate_video(image, prompt):\n",
    "    # Converting the image to bytes\n",
    "    image_bytes_io = io.BytesIO()\n",
    "    image.save(image_bytes_io, format=image.format)\n",
    "    image_bytes = image_bytes_io.getvalue()\n",
    "\n",
    "    operation = client.models.generate_videos(\n",
    "        model=\"veo-3.0-generate-001\", # veo-3.0-generate-001, veo-3.0-fast-generate-001\n",
    "        prompt=prompt,\n",
    "        image=types.Image(image_bytes=image_bytes, mime_type=image.format),\n",
    "        config=types.GenerateVideosConfig(\n",
    "            aspect_ratio=\"16:9\",\n",
    "            number_of_videos=1))\n",
    "    \n",
    "    while not operation.done:\n",
    "        print(\"Waiting for video generation to complete...\")\n",
    "        time.sleep(10)\n",
    "        operation = client.operations.get(operation)\n",
    "\n",
    "    return operation.result.generated_videos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capable of editing and generating.\n",
    "result = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-image\", # gemini-2.5-flash-image-preview\n",
    "    contents=[prompt, img_in]\n",
    ")\n",
    "\n",
    "for part in result.candidates[0].content.parts:\n",
    "    if part.text:\n",
    "        print(part.text)\n",
    "    elif part.inline_data is not None:\n",
    "        image = Image.open(BytesIO(part.inline_data.data))\n",
    "        image.save(\"docs/results/img_out.png\")\n",
    "\n",
    "Image.open(\"docs/results/img_out.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyria_client = genai.Client(\n",
    "    api_key=GOOGLE_API_KEY,\n",
    "    http_options={'api_version': 'v1alpha'}, # Lyria is only experimental.\n",
    ")\n",
    "\n",
    "music_prompts = [\n",
    "    {\"text\": \"Piano\", \"weight\": 2.0},\n",
    "    types.WeightedPrompt(text=\"Meditation\", weight=0.5),\n",
    "    types.WeightedPrompt(text=\"Live Performance\", weight=1.0),\n",
    "]\n",
    "\n",
    "music_config = types.LiveMusicGenerationConfig(\n",
    "    bpm=128,\n",
    "    scale=types.Scale.D_MAJOR_B_MINOR,\n",
    "    music_generation_mode=types.MusicGenerationMode.QUALITY\n",
    ")\n",
    "\n",
    "async def generate_music(prompts: list, config: types.LiveMusicGenerationConfig):\n",
    "    # Background task to process incoming audio.\n",
    "    async def receive_audio(session):\n",
    "        while True:\n",
    "            async for message in session.receive():\n",
    "                audio_data = message.server_content.audio_chunks[0].data\n",
    "                # Process audio...\n",
    "                await asyncio.sleep(10**-12)\n",
    "\n",
    "    async with (\n",
    "        lyria_client.aio.live.music.connect(model='models/lyria-realtime-exp') as session,\n",
    "        asyncio.TaskGroup() as tg,\n",
    "    ):\n",
    "        # Set up task to receive server messages.\n",
    "        tg.create_task(receive_audio(session))\n",
    "\n",
    "        # Send initial prompts and config\n",
    "        await session.set_weighted_prompts(prompts=music_prompts)\n",
    "        await session.set_music_generation_config(config=config)\n",
    "\n",
    "        # Start streaming music\n",
    "        await session.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.run(generate_music(music_prompts, music_config))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
